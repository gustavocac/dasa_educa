{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled9.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNd4LiDcOX/J50DFcdIuOap",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gustavocac/dasa_educa/blob/master/last.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rncof10uxEmc"
      },
      "source": [
        "**Pub MED Scrapping**</br>\n",
        "Execute a célula inferior com CTRL + ENTER</br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4JX-ThefOe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "import random\n",
        "from pymongo import MongoClient\n",
        "import pandas as pd\n",
        "import multiprocessing as mp\n",
        "\n",
        "UserAgent = [\n",
        "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\",\n",
        "        \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:55.0) Gecko/20100101 Firefox/55.0\",\n",
        "        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.101 Safari/537.36\",\n",
        "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\",\n",
        "        \"Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11\",\n",
        "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6\",\n",
        "        \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6\",\n",
        "        \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1\",\n",
        "        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5\",\n",
        "        \"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5\",\n",
        "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\n",
        "        \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\n",
        "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\n",
        "        \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3\",\n",
        "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3\",\n",
        "        \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n",
        "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n",
        "        \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n",
        "        \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3\",\n",
        "        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24\",\n",
        "        \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24\"\n",
        "        ]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZLvSun-f4yc",
        "colab_type": "text"
      },
      "source": [
        "**Deu erro?**</br>\n",
        "Execute a célula inferior e depois a superior novamente.</br>\n",
        "Aliás isso é um markdown!\n",
        "A exclamação é usada para ativar o modo comando terminal na linha. Que é o equivalente ao DOS, nessa plataforma. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzkLeD8Khjpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1eyrj-xyd4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "options = Options()\n",
        "options.add_argument(\"--headless\") # Runs Chrome in headless mode.\n",
        "options.add_argument('--no-sandbox') # Bypass OS security model\n",
        "options.add_argument('--disable-gpu')  # applicable to windows os only\n",
        "options.add_argument('start-maximized') # \n",
        "options.add_argument('disable-infobars')\n",
        "options.add_argument(\"--disable-extensions\")\n",
        "wd = webdriver.Chrome('chromedriver',options=options)\n",
        "wd.get(\"http://www.uol.com.br\")\n",
        "page_source_html = wd.page_source\n",
        "# print page source html code.\n",
        "#print(page_source_html)\n",
        "# close and quit google chrome.\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(page_source_html))\n",
        "wd.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfMb6viBfeWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def singlePageExtract(url):\n",
        "    # Get author's organization and paper keywords\n",
        "    org = ''\n",
        "    \n",
        "    print(url)\n",
        "    # Set waiting time to avoid high traffic\n",
        "    browser.implicitly_wait(random.randint(2, 3))\n",
        "    \n",
        "    # Get target page information\n",
        "    tempo_html = requests.get(url,  headers = requestHeader(url))\n",
        "    tempo_soup = BeautifulSoup(tempo_html.text, 'lxml')\n",
        "    \n",
        "    # Find and collect authors' organization\n",
        "    try:\n",
        "        collect = tempo_soup.find('dl', {'class':'ui-ncbi-toggler-slave'}).find_all('dd')\n",
        "        for single in collect:\n",
        "            org += ';' + single.get_text()\n",
        "    except:\n",
        "        org = 'ORGANIZATION_NA'\n",
        "    \n",
        "    # Collect article' keywords\n",
        "    try:\n",
        "        keywords = tempo_soup.find('div', {'class':'keywords'}).find('p').get_text().split(';')\n",
        "    except:\n",
        "        keywords = 'KEYWORDS_NA'\n",
        "    \n",
        "    return org, keywords\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S56pwcoZg1D0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def requestHeader(url):\n",
        "    # Build request headers\n",
        "    headers = {\n",
        "            'User-Agent':random.choice(UserAgent),\n",
        "            'Referer': url,\n",
        "            'Connection':'keep-alive',\n",
        "            'Host':'www.ncbi.nlm.nih.gov'\n",
        "            }\n",
        "    return headers\n",
        "\n",
        "    \n",
        "def getMaxPageNum(searchWord):\n",
        "    # Build search link\n",
        "    url = 'https://www.ncbi.nlm.nih.gov/pubmed/?term=' + searchWord\n",
        "    \n",
        "    browser.get(url)\n",
        "    browser.implicitly_wait(1)\n",
        "    \n",
        "    # Get maximum page number from returned research result\n",
        "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "    max_num = int(soup.find('input', {'id':'pageno2'}).get('last'))\n",
        "    return max_num\n",
        "    \n",
        "\n",
        "def multiCore(url_list):\n",
        "    # Multiprocessing\n",
        "    p = mp.Pool()\n",
        "\n",
        "    for url in url_list:\n",
        "        p.apply_async(extractWrite, args=(url,))\n",
        "\n",
        "    # Close pool\n",
        "    p.close()\n",
        "    p.join()\n",
        "\n",
        "\n",
        "def extractWrite(url):\n",
        "    # Extract information and write into MongoDB\n",
        "    org, keywords = singlePageExtract(url)\n",
        "    # Extract title, author, date and other information\n",
        "    title = row.find('a').get_text()\n",
        "    author = row.find('p', {'class':'desc'}).get_text()\n",
        "    journal = row.find('span', {'class':'jrnl'}).get('title')\n",
        "    date_raw = row.find('p', {'class':'details'}).get_text()\n",
        "    # Use regular expression to get time information\n",
        "    date = re.findall(r'\\d{4}[\\s\\w{3}\\s\\d+]*', date_raw)[0]\n",
        "\n",
        "    # Build data to be loaded into MongoDB\n",
        "    data = {\n",
        "    'url': link,\n",
        "    'title': title,\n",
        "    'author': author,\n",
        "    'journal': journal,\n",
        "    'date': date,\n",
        "    'org': org,\n",
        "    'keywords': keywords\n",
        "    }\n",
        "\n",
        "    # Check if already existed\n",
        "    if db.med_nlp.find({'url': link}).limit(1):\n",
        "    \tprint(data, 'already exists.')\n",
        "    else:\n",
        "        # Insert data into MongoDB's Pubmed database's med_nlp collections\n",
        "        db.med_nlp.insertOne(data)  \n",
        "\n",
        "\n",
        "def informationExtraction():\n",
        "    # Extract and build data \n",
        "    # Parse html information\n",
        "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "    # Find sections with desired information\n",
        "    all_div = soup.find_all('div', {'class':'rslt'})\n",
        "\n",
        "    # Create/empty url_list to store all the new urls\n",
        "    url_list = []\n",
        "    \n",
        "    # Iterate to extract information like author, title, journal, etc\n",
        "    for row in all_div:\n",
        "        # Build article's individual link\n",
        "        link = default_link + row.find('a').get('href')\n",
        "        url_list.append(link)\n",
        "    \n",
        "    # Operate multiprocessing\n",
        "    multiCore(url_list)\n",
        "\n",
        "    browser.implicitly_wait(1)\n",
        "\n",
        "    # Click next buttion to navigate to the next page\n",
        "    browser.find_element_by_xpath('//*[@title=\"Next page of results\"]').click()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtNDi4e_g8Iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Website to scrape\n",
        "    default_link = 'https://www.ncbi.nlm.nih.gov'\n",
        "\n",
        "    # Start web browser\n",
        "    browser = webdriver.Chrome('chromedriver',options=options)\n",
        "\n",
        "\n",
        "    # Start MongoDB\n",
        "    MONGO_HOST= 'mongodb://localhost:27017/'\n",
        "    client = MongoClient(MONGO_HOST)\n",
        "\n",
        "    # Create or load Pubmed database\n",
        "    db = client.Pubmed\n",
        "\n",
        "    # Get input\n",
        "    searchKeyWords = input(\"Please input your search key words/phrases!\")\n",
        "\n",
        "    # By default\n",
        "    # searchKeyWords = 'natural language processing clinical'\n",
        "\n",
        "    # Get max page number\n",
        "    max_number = getMaxPageNum(searchKeyWords)\n",
        "\n",
        "    count = 1\n",
        "\n",
        "    while count < max_number:\n",
        "        print(count)\n",
        "        informationExtraction()\n",
        "        count += 1\n",
        "        #se apagar ou comentar essas duas linhas a seguir ele busca todas as imagens. \n",
        "        if count >=1:\n",
        "          break\n",
        "\n",
        "    print(\"finish\")\n",
        "\n",
        "## Access MongdoDB to analyze data   \n",
        "#conn = MongoClient(host='localhost',port=27017)\n",
        "#pub = conn['Pubmed']\n",
        "#nlp = pub['med_nlp']\n",
        "#\n",
        "#data = pd.DataFrame(list(nlp.find()))\n",
        "#print(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFszdGmtcFD_",
        "colab_type": "text"
      },
      "source": [
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNSxenrBmXvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cdw1WNbfvpdW",
        "colab": {}
      },
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Website to scrape\n",
        "    default_link = 'https://www.ncbi.nlm.nih.gov'\n",
        "\n",
        "    # Start web browser\n",
        "    browser = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "\n",
        "\n",
        "    # Start MongoDB\n",
        "    MONGO_HOST= 'mongodb://localhost:27017/'\n",
        "    client = MongoClient(MONGO_HOST)\n",
        "\n",
        "    # Create or load Pubmed database\n",
        "    db = client.Pubmed\n",
        "\n",
        "    # Get input\n",
        "    searchKeyWords = input(\"Please input your search key words/phrases!\")\n",
        "\n",
        "    # By default\n",
        "    # searchKeyWords = 'natural language processing clinical'\n",
        "\n",
        "    # Get max page number\n",
        "    max_number = getMaxPageNum(searchKeyWords)\n",
        "\n",
        "    count = 1\n",
        "\n",
        "    while count < max_number:\n",
        "        print(count)\n",
        "        informationExtraction()\n",
        "        count += 1\n",
        "        if count >=3:\n",
        "          break\n",
        "\n",
        "    print(\"finish\")\n",
        "\n",
        "## Access MongdoDB to analyze data   \n",
        "#conn = MongoClient(host='localhost',port=27017)\n",
        "#pub = conn['Pubmed']\n",
        "#nlp = pub['med_nlp']\n",
        "#\n",
        "#data = pd.DataFrame(list(nlp.find()))\n",
        "#print(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFibL4SxuyBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pymongo\n",
        "MONGO_HOST= 'mongodb://localhost:27017/'\n",
        "client = MongoClient(MONGO_HOST)\n",
        "mycol = mydb[\"customers\"]\n",
        "\n",
        "\n",
        "for x in mycol.find():\n",
        "  print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxAD9Eg7cTHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conn = MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)\n",
        "pub = conn['Pubmed']\n",
        "nlp = pub['med_nlp']\n",
        "data = pd.DataFrame(list(nlp.find()))\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}